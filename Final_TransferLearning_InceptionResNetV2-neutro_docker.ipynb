{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Input, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE=299\n",
    "CHANNEL=3\n",
    "IMAGE_SHAPE=(SIZE, SIZE, CHANNEL)\n",
    "\n",
    "BATCH_SIZE=4\n",
    "EPOCHS=50\n",
    "\n",
    "train_dir=\"D:/Datasets/Neutrophil-dataset/NeutrophilImages_split/neutrophil_train\"\n",
    "valid_dir=\"D:/Datasets/Neutrophil-dataset/NeutrophilImages_split/neutrophil_validiation\"\n",
    "test_dir=\"D:/Datasets/Neutrophil-dataset/NeutrophilImages_split/neutrophil_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 157 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255,\n",
    "                                  rotation_range=10,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=True)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(train_dir,\n",
    "                                                   target_size=(SIZE, SIZE),\n",
    "                                                   color_mode=\"rgb\",\n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   seed=19,\n",
    "                                                   shuffle=True,\n",
    "                                                   class_mode=\"categorical\")\n",
    "\n",
    "valid_datagen=ImageDataGenerator(rescale=1./255)\n",
    "valid_generator=valid_datagen.flow_from_directory(valid_dir,\n",
    "                                                  target_size=(SIZE, SIZE),\n",
    "                                                  color_mode=\"rgb\",\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "                                                  seed=19,\n",
    "                                                  shuffle=True,\n",
    "                                                  class_mode=\"categorical\")\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "test_generator=test_datagen.flow_from_directory(test_dir,\n",
    "                                                  target_size=(SIZE, SIZE),\n",
    "                                                  color_mode=\"rgb\",\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "                                                  seed=19,\n",
    "                                                  shuffle=True,\n",
    "                                                  class_mode=\"categorical\")\n",
    "\n",
    "train_num=train_generator.samples\n",
    "valid_num=valid_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciando modelo a partir de InceptionResNetV2\n",
    "\n",
    "inception_model=InceptionResNetV2(input_shape=(299, 299, 3), weights='imagenet', include_top=False, classes=2)\n",
    "\n",
    "for layer in inception_model.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o otimizador para compilar o modelo\n",
    "OPT=Adam(learning_rate=1e-5) # learning_rate default = 0.001\n",
    "\n",
    "# Adicionando novas camadas nas parte final do modelo\n",
    "in_layer=Input(shape=IMAGE_SHAPE,dtype=tf.uint8)\n",
    "x=tf.cast(in_layer, tf.float32)\n",
    "x=preprocess_input(x)\n",
    "\n",
    "x=inception_model(x, training=False)\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "dense_layer=Dense(64, activation='relu', kernel_initializer='he_normal')(x)\n",
    "drop_out=Dropout(0.4)(dense_layer)\n",
    "out_layer=Dense(2, activation='softmax')(drop_out)\n",
    "\n",
    "\n",
    "# Instanciando o modelo final com as devidas ateracoes\n",
    "model=Model(inputs=in_layer, outputs=out_layer)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=OPT, \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-c74fc6ab18b7>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 0.7332 - accuracy: 0.5229 - val_loss: 0.6871 - val_accuracy: 0.5500\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 6s 141ms/step - loss: 0.7064 - accuracy: 0.5621 - val_loss: 0.6237 - val_accuracy: 0.5500\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 5s 140ms/step - loss: 0.7043 - accuracy: 0.4967 - val_loss: 0.5661 - val_accuracy: 0.5500\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.6023 - accuracy: 0.6154 - val_loss: 0.5182 - val_accuracy: 0.5500\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 6s 141ms/step - loss: 0.5365 - accuracy: 0.7190 - val_loss: 0.4739 - val_accuracy: 0.9500\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 6s 144ms/step - loss: 0.5196 - accuracy: 0.7386 - val_loss: 0.4374 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 6s 142ms/step - loss: 0.5280 - accuracy: 0.7908 - val_loss: 0.4052 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 6s 147ms/step - loss: 0.4904 - accuracy: 0.8562 - val_loss: 0.3733 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 6s 147ms/step - loss: 0.4609 - accuracy: 0.8627 - val_loss: 0.3445 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 6s 145ms/step - loss: 0.4428 - accuracy: 0.8693 - val_loss: 0.3188 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 6s 142ms/step - loss: 0.4066 - accuracy: 0.9346 - val_loss: 0.2959 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 6s 141ms/step - loss: 0.3800 - accuracy: 0.9412 - val_loss: 0.2744 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 6s 142ms/step - loss: 0.3777 - accuracy: 0.9150 - val_loss: 0.2575 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.3516 - accuracy: 0.9477 - val_loss: 0.2421 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 6s 142ms/step - loss: 0.3092 - accuracy: 0.9804 - val_loss: 0.2290 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 6s 142ms/step - loss: 0.3262 - accuracy: 0.9346 - val_loss: 0.2160 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 6s 144ms/step - loss: 0.3151 - accuracy: 0.9615 - val_loss: 0.2036 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.3079 - accuracy: 0.9542 - val_loss: 0.1930 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.2999 - accuracy: 0.9412 - val_loss: 0.1815 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.2786 - accuracy: 0.9804 - val_loss: 0.1657 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 6s 142ms/step - loss: 0.2800 - accuracy: 0.9739 - val_loss: 0.1533 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.2728 - accuracy: 0.9804 - val_loss: 0.1453 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.2529 - accuracy: 0.9935 - val_loss: 0.1375 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.2855 - accuracy: 0.9608 - val_loss: 0.1299 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.2275 - accuracy: 0.9804 - val_loss: 0.1242 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.2084 - accuracy: 0.9935 - val_loss: 0.1180 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 6s 142ms/step - loss: 0.2177 - accuracy: 0.9935 - val_loss: 0.1123 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.2153 - accuracy: 0.9739 - val_loss: 0.1070 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 6s 141ms/step - loss: 0.2173 - accuracy: 0.9869 - val_loss: 0.1021 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 6s 142ms/step - loss: 0.1854 - accuracy: 0.9869 - val_loss: 0.0974 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 6s 141ms/step - loss: 0.1815 - accuracy: 0.9935 - val_loss: 0.0928 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 6s 142ms/step - loss: 0.1922 - accuracy: 0.9739 - val_loss: 0.0887 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 6s 145ms/step - loss: 0.1947 - accuracy: 0.9804 - val_loss: 0.0852 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.1646 - accuracy: 0.9804 - val_loss: 0.0817 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.1889 - accuracy: 0.9869 - val_loss: 0.0783 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 6s 145ms/step - loss: 0.1639 - accuracy: 0.9869 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.1672 - accuracy: 0.9869 - val_loss: 0.0716 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.1524 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 6s 142ms/step - loss: 0.1749 - accuracy: 0.9935 - val_loss: 0.0648 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.1353 - accuracy: 0.9869 - val_loss: 0.0617 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.1496 - accuracy: 0.9935 - val_loss: 0.0598 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 6s 142ms/step - loss: 0.1568 - accuracy: 0.9869 - val_loss: 0.0577 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.1321 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 6s 142ms/step - loss: 0.1706 - accuracy: 0.9673 - val_loss: 0.0540 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.1211 - accuracy: 0.9935 - val_loss: 0.0514 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 6s 142ms/step - loss: 0.1506 - accuracy: 0.9739 - val_loss: 0.0495 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 6s 142ms/step - loss: 0.1286 - accuracy: 0.9935 - val_loss: 0.0476 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.1139 - accuracy: 0.9869 - val_loss: 0.0458 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 6s 143ms/step - loss: 0.1379 - accuracy: 0.9804 - val_loss: 0.0442 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 6s 145ms/step - loss: 0.0966 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x187fb1ebb20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator,\n",
    "                   epochs=EPOCHS,\n",
    "                   steps_per_epoch=train_num // BATCH_SIZE,\n",
    "                   validation_data=valid_generator,\n",
    "                   validation_steps=valid_num // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/5 [===========>..................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0170s vs `on_predict_batch_end` time: 0.1260s). Check your callbacks.\n",
      "5/5 [==============================] - 1s 155ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.64      0.64      0.64        11\n",
      "          N2       0.56      0.56      0.56         9\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.60      0.60      0.60        20\n",
      "weighted avg       0.60      0.60      0.60        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Avaliacoes sobre o modelo\n",
    "\n",
    "# Tendo acesso ao \"ground truth\" do dataset para teste\n",
    "y_true=test_generator.labels\n",
    "\n",
    "# Prevendo a propabilidade da distribuicao do dataset\n",
    "prediction=model.predict(test_generator, verbose=1)\n",
    "\n",
    "# Pegando a classe com maior probabilidade para cada exemplo\n",
    "y_pred=np.argmax(prediction, axis=1)\n",
    "\n",
    "# Gerando o relatorio de classificacao\n",
    "print(classification_report(y_true, y_pred, target_names=['N1', 'N2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAEYCAYAAACpy8geAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWU0lEQVR4nO3debxVZb3H8c8XUBFBUAEHAsdSLGcSh0IkrSi1crgOeE2za+otr1NWVzO0zMLLTU27aXUzcsYoFecc0kxNVCRBvWqiIJagIoOIDL/7x3qObjb77PMcYQ9wvu/X67zOWutZe63fnr77Wc/ea29FBGZmOTo1ugAzW3U4MMwsmwPDzLI5MMwsmwPDzLI5MMwsmwOjASSNkHTnStjOFZJ+sDJqWhkkrS3pZklvSRq7gts6W9LLkraTdO/KqtFWjAMjkTRV0ruSepctf0JSSNosYxubpXW7VFsvIq6KiE+vYMnN6GBgQ2CDiDhkBbe1PTAM+AnwwAfdiKT7JL0jqX/Jsn0kTS2Z/7qkCZIWSrpiBWpuT11Hp8fKGWXLp0samqa/LOkxSXPS8lFtPbZqzYGxrBeBw1tmJG0HdFuZO2j0HV5jmwL/FxGLV3RDEXFwRDwfEftExNkruLn5wHertM8AfgD87wrup73eAM6Q1KOV9m7AyUBvYDDwKeD0+pRWmQNjWb8FjiqZ/zIwpnQFSZ9PvY45kqZJGlnSfH/6P1vSPEm7p1eSByX9RNLrwMi07M9pe2ekdVv+FrX2KidpJ0mPS5or6Tqga1n7fpImSpot6S+Stm/tikr6qKS7JL0h6Z+S/jMtX0vShZJmpL8LJa2V2oamV7rTJL0m6VVJx6S2c4CzgUPT9ThW0khJV5bsc5keWLod/p6uz4uSRqTlW0q6R9LrkmZJukpSr5LtDEw9h9mSJks6oLXrmVwMHC5py0qNETEuIv4AvN7GdpD0tKT9Sua7SJopaWdJXSVdmeqeLelRSRtW2dzTwEPAqa3U9T8R8UBEvBsRrwBXAXu2VWMtOTCW9TCwbnpAdgYOA64sW2c+Raj0Aj4PnCDpi6ltSPrfKyK6R8RDaX4w8HeK7vp5pRuLiFFp3e7AQGAmcF15YZLWBP5AEWrrA2OBg0rad6J4hfwasAFwGXBTy5O9bFs9gD8CtwObAFsBd6fmM4HdgB2BHYBdgbNKLr4R0BPoBxwLXCppvYj4HvBD4Lp0fX5Vvt+yGtaheCIPj4gewB7AxJZm4PxU20CgPzAyXW4N4GbgTqAv8A3gKklbV9ndK8AvgHOq1ZTpGkp6ocBngFkR8TjFC0zPVO8GwPHAgja2913gZEnrZ+x7CDC53RWvRA6M5bX0MvaleAV4pbQxIu6LiL9FxNKImETxANqrjW3OiIifRsTiiKj4AJK0NkUgXBQRt1VYZTdgDeDCiFgUETcAj5a0HwdcFhGPRMSSiPgNsDBdrtx+wD8iYnREvBMRcyPikdQ2Ajg3Il6LiJkUT7J/LbnsotS+KCJuBeYB1Z6s1SwFPiZp7Yh4NSImA6RDkbsiYmGq4b95/zbeDegO/Ci98t4DjGfZJ3El5wP7S/roB6y1xdXAAZJaDlWPoHgMQHHbbABsle6DxyJiTrWNRcRE4C7gW9XWk/QVYBDwXytQ+wpzYCzvtxQPgqMpOxwBkDRY0r2pG/oWxatI7/L1ykzL2O+vgGcj4settG8CvBLLni34Usn0psBpqSs8W9Jsile6TSpsqz/wQpX9lG73pbJtvF42RvE2xRO4XSJiPnAoxe33qqRbJG0DIGlDSddKekXSHIpeXsttvAkwLSKWltXYr439zQQuAc5tT52Sbis5XBwREc9TvJDsn0LjAIoQgeKxcwdwbTqcGyVpDUmfLNlGpR7C2RQ91YqHL6kHez5Fb2xWe+pf2RwYZSLiJYrBz88B4yqscjVwE9A/InoCP6foQgO0dupv1VOCJX0b+AhFF781rwL9JKlk2YCS6WnAeRHRq+SvW0Rcw/KmAVu0sp8ZFOFTuo8Z1eqvYj7LDhpvVNoYEXdExL7AxsAzFIcNUBzaBLBdRKwLHMn7t/EMoL+k0sfuAMp6gq24ANgb2CX3CkTE8JZDxoi4Ki1uOSz5AjAlhQip13VORGxLcYi1H3BUGodo2cZyPZyIeIbisXZmeZukz1LcLvtHxN9y664VB0ZlxwLD0qtguR7AGxHxjqRdKXojLWZSdLNbezIuR9Jw4CTgS60driQPAYuBk9Kr1oEU4wstfgEcn3pAkrSOigHaSiPw44GNJZ2cBjl7SBqc2q4BzpLUR8VbzGez/DhOronAEEkDJPUEvlNyvTeU9IU0lrGQ4tCmpdfQI82/Jakf8M2SbT5C0as5I90OQ4H9gWvbKiYiZgOjgfK3MrtI6gp0Bjqnwctq72ZdC3waOIH3exdI2lvF50Y6A3MoDlGWVt7Ecs4BjqEYG2vZ3jCKgc6DIuKvmdupKQdGBRHxQkRMaKX5ROBcSXMpnkzXl1zubYpBzQfTYUGl8YNyhwJ9gKdLuq0/r1DTu8CBFIdKb6TLjStpnwD8G0W3+03g+bRupes3l2KMZn/gH8BzFK+8ULy9OAGYBPwNeDwta7eIuItiAHcS8BhFULXoRPHuwIx0ffaieAJC8eTZGXgLuKXser6b6h4OzAJ+RvEq/kxmWRcBS8qWnUUxOPltit7MApYd6C2/Xq9SBPgeLDtAvRFwA0VYPA38ieIwpU0R8WJad52Sxd+lGES9teSxUWl8q27kL9Axs1zuYZhZNgeGmWVzYJhZNgeGmWVbZU6EUpe1Q2u2do6ONaudBg5oeyVrKi+9NJVZs2apUtuqExhr9mCtrf+l0WVYOz34yCWNLsHaac/Bg1pt8yGJmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZNgeGmWVzYJhZti6NLqAjW/rOmyyaesd78/HuHLpsNJgufXdoYFWWY8mSJew5eBCb9OvHuBvHN7qcunFgNFCnruux1jaHARCxlIWTr6Bzr80bXJXluOTii9h64EDmzpnT6FLqyockTWLp3OlorZ5ozXUbXYq1Yfr06dx+2y0c85WvNrqUunNgNImls5+jc68PN7oMy/DN007mvPNH0alTx3v61OwaSwpJo0vmT5c0Mk0PkfS4pMWSDq5VDauKWLqEJW9NpXOvrRpdirXh1lvG07dPX3beZZdGl9IQtYzIhcCBknpXaHsZOBq4uob7X2UsnfsSnbr1QWt0a3Qp1oaH/vIg48ffxNZbbcZRIw7jvnvv4Zijjmx0WXVTy8BYDFwOnFLeEBFTI2ISsLSG+19lLHnzOTr5cGSV8P3zzueFqdN59vmpjLnqWobuPYxfj7my0WXVTa0Pwi4FRkjq+UEuLOk4SRMkTYjFC1Zyac0hlixi6dxpdO61RaNLMWtTTd9WjYg5ksYAJwHtfsZHxOUUvRQ6desbK7m8pqDOa9B1u4432r46GLLXUIbsNbTRZdRVPYZ5LwSOBdapw77MrIZqHhgR8QZwPUVomNkqrF5vJI8G3nu3RNLHJU0HDgEukzS5TnWY2Qqo2RhGRHQvmf4n0K1k/lHgQ7Xat5nVRsf7qJqZfWAODDPL5sAws2wODDPL5sAws2wODDPL5sAws2wODDPL5sAws2wODDPL5sAws2wODDPL5sAws2wODDPL5sAws2wODDPL5sAws2wODDPL5sAws2wODDPL5sAws2wODDPL5sAws2wODDPL5sAws2wODDPL5sAws2yt/raqpJ8C0Vp7RJxUk4rMrGlV+zHmCXWrwsxWCa0GRkT8pnReUreIeLv2JZlZs2pzDEPS7pKmAM+k+R0k/azmlZlZ08kZ9LwQ+AzwOkBEPAkMqWFNZtakst4liYhpZYuW1KAWM2ty1QY9W0yTtAcQktYA/gN4urZlmVkzyulhHA/8O9APmAHsmObNrINps4cREbOAEXWoxcyaXM67JFtIulnSTEmvSbpR0hb1KM7MmkvOIcnVwPXAxsAmwFjgmloWZWbNKScwukXEbyNicfq7Euha68LMrPlUO5dk/TR5m6RvA9dSnFtyKHBrHWozsyZTbdDzMYqAUJr/WklbAN+pVVFm1pyqnUuyeT0LMbPml/PBLSR9DNiWkrGLiBhTq6LMrDm1GRiSvgcMpQiMW4HhwJ8BB4ZZB5PzLsnBwKeAf0TEMcAOQM+aVmVmTSknMBZExFJgsaR1gdeA/rUty8yaUc4YxgRJvYBfULxzMg94qJZFmVlzyjmX5MQ0+XNJtwPrRsSk2pZlZs2o2ge3dq7WFhGP16YkM2tW1XoYo6u0BTBsJddS1U4DB/DgI5fUc5e2Eox/akajS7B2mr1gUatt1T64tXdNqjGzVZZ/yMjMsjkwzCybA8PMsuV845YkHSnp7DQ/QNKutS/NzJpNTg/jZ8DuwOFpfi5wac0qMrOmlfNJz8ERsbOkJwAi4k1Ja9a4LjNrQjk9jEWSOpN+yV1SH2BpTasys6aUExgXA78H+ko6j+LU9h/WtCoza0o555JcJekxilPcBXwxIvzLZ2YdUM4X6AwA3gZuLl0WES/XsjAzaz45g5638P6XAXcFNgeeBT5aw7rMrAnlHJJsVzqfzmI9sZXVzWw11u5PeqbT2gfXoBYza3I5Yxinlsx2Anam+BV3M+tgcsYwepRML6YY0/hdbcoxs2ZWNTDSB7Z6RMTpdarHzJpYq2MYkrpExBJgzzrWY2ZNrFoP468U4xUTJd0EjAXmtzRGxLga12ZmTSZnDKMr8DrFd3i2fB4jAAeGWQdTLTD6pndInmLZX3EnzZtZB1MtMDoD3Vk2KFo4MMw6oGqB8WpEnFu3Ssys6VX7pGelnoWZdWDVAuNTdavCzFYJrQZGRLxRz0LMrPn5ZwbMLJsDw8yyOTDMLJsDw8yyOTDMLJsDw8yyOTDMLJsDw8yyOTDMLJsDw8yyOTDMLJsDw8yyOTDMLJsDw8yyOTDMLJsDw8yyOTDMLJsDw8yyOTDMLJsDw8yyOTDMLFvOb6taDS1ZsoQ9Bw9ik379GHfj+EaXYxlO/Nxguq7TnU6dOtG5cxd+fPVtjS6pbhwYDXbJxRex9cCBzJ0zp9GlWDuMvHws6663fqPLqDsfkjTQ9OnTuf22WzjmK19tdClmWdzDaKBvnnYy550/innz5ja6FGsPiR+ceDhI7HvQkex70JGNrqhuatbDkBSSRpfMny5pZJo+VdIUSZMk3S1p01rV0axuvWU8ffv0Zedddml0KdZO3//17xl1zR2cecmV3HHdFUx57OFGl1Q3tTwkWQgcKKl3hbYngEERsT1wAzCqhnU0pYf+8iDjx9/E1lttxlEjDuO+e+/hmKM6zivVqmyDvhsD0HP93uw6bDjPT57Y2ILqqJaBsRi4HDilvCEi7o2It9Psw8CHalhHU/r+eefzwtTpPPv8VMZcdS1D9x7Gr8dc2eiyrA3vLHibBfPnvTf95EN/ov+WWze4qvqp9RjGpcAkSdV6EMcCFd+XknQccBxA/wEDVn51Zu301uszueDUY4HiLfFPDP8iO+25d4Orqh9FRG02LM2LiO6SzgUWAQuA7hExsmSdI4GvA3tFxMJq29tll0Hx4CMTalKr1c74p2Y0ugRrp28dMZwXpjypSm31eFv1QopexDqlCyXtA5wJHNBWWJhZc6h5YETEG8D1FKEBgKSdgMsowuK1WtdgZitHvT64NRoofbfkAqA7MFbSREk31akOM1sBNRv0jIjuJdP/BLqVzO9Tq/2aWe34o+Fmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmls2BYWbZHBhmlk0R0egaskiaCbzU6DpqpDcwq9FFWLutrvfbphHRp1LDKhMYqzNJEyJiUKPrsPbpiPebD0nMLJsDw8yyOTCaw+WNLsA+kA53v3kMw8yyuYdhZtkcGGaWzYFRR5JC0uiS+dMljUzTQyQ9LmmxpIMbVqQtp4377VRJUyRNknS3pE0bVmgdODDqayFwoKTeFdpeBo4Grq5rRZaj2v32BDAoIrYHbgBG1bWyOnNg1NdiipH1U8obImJqREwClta9KmtLtfvt3oh4O80+DHyonoXVmwOj/i4FRkjq2ehCrF1y7rdjgdvqVE9DdGl0AR1NRMyRNAY4CVjQ6HosT1v3m6QjgUHAXvWurZ7cw2iMCylejdZpcB3WPhdS4X6TtA9wJnBARCxsQF1148BogIh4A7ie4sFnq4hK95uknYDLKMLitUbVVi8OjMYZTXF6NACSPi5pOnAIcJmkyQ2rzKpZ5n4DLgC6A2MlTZR0U2PKqg9/NNzMsrmHYWbZHBhmls2BYWbZHBhmls2BYWbZHBirGUlL0tt7T0kaK6nbCmzripYzZyX9UtK2VdYdKmmPD7CPqZVO6mptedk689q5r5GSTm9vjfY+B8bqZ0FE7BgRHwPeBY4vbZT0gU4HiIivRsSUKqsMBdodGLZqcWCs3h4Atkqv/g+kDxVNkdRZ0gWSHk3f4/A1ABUukfSspD8CfVs2JOk+SYPS9GfTd3c8mb4DYjOKYDol9W4+KamPpN+lfTwqac902Q0k3SlpsqRfAmrrSkj6g6TH0mWOK2v7SVp+t6Q+admWkm5Pl3lA0jYr5dY0iAj/rUZ/wLz0vwtwI3ACxav/fGDz1HYccFaaXguYAGwOHAjcBXQGNgFmAwen9e6jOLmqDzCtZFvrp/8jgdNL6rga+ESaHgA8naYvBs5O058HAuhd4XpMbVleso+1gaeADdJ8ACPS9NnAJWn6buDDaXowcE+lGv3X/j+frbr6WVvSxDT9APArikOFv0bEi2n5p4HtS77ZqyfwYWAIcE1ELAFmSLqnwvZ3A+5v2VYU51dUsg+wrfReB2JdSd3TPg5Ml71F0psZ1+kkSV9K0/1Tra9TfHfIdWn5lcC4tI89KD6q3XL5tTL2YRkcGKufBRGxY+mC9MSZX7oI+EZE3FG23udWYh2dgN0i4p0KtWSTNJQifHaPiLcl3Qd0bWX1SPudXX4b2MrhMYyO6Q7gBElrAEj6iKR1gPuBQ9MYx8bA3hUu+zAwRNLm6bLrp+VzgR4l690JfKNlRtKOafJ+4Ii0bDiwXhu19gTeTGGxDUUPp0UnoKWXdATw54iYA7wo6ZC0D0naoY19WCYHRsf0S2AK8LikpyhOz+4C/B54LrWNAR4qv2BEzKQYAxkn6UnePyS4GfhSy6AnxRfNDEqDqlN4/92acygCZzLFocnLbdR6O9BF0tPAjygCq8V8YNd0HYYB56blI4BjU32TgS9k3CaWwWermlk29zDMLJsDw8yyOTDMLJsDw8yyOTDMLJsDw8yyOTDMLNv/A/r6e7RR50BaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Elaborando plot para matriz de confusão\n",
    "class_names=['N1', 'N2']\n",
    "cm=confusion_matrix(y_true, y_pred)\n",
    "title=\"Matriz de confusão N1-vs-N2\"\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(title)\n",
    "tick_marks=np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "thresh=cm.max()/2\n",
    "\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"black\")\n",
    "             #color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pickle_out = open(\"model.pkl\",\"wb\")\n",
    "pickle.dump(model, pickle_out)\n",
    "pickle_out.close()\n",
    "'''\n",
    "\n",
    "model.save('neut_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 (neutroT)",
   "language": "python",
   "name": "neutrot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
